{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqw5hHtuywXGqU9waxjAS5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redfear08/bot_trade_ml/blob/main/trading_bot_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install -q pandas scikit-learn tensorflow kiteconnect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3Wp1sPzWFge",
        "outputId": "d1b5d71c-b4dd-4cc3-b193-bee64a679958"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m771.5/771.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.8/247.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Authentication and data fetching\n",
        "import pandas as pd\n",
        "from kiteconnect import KiteConnect\n",
        "import datetime as dt\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "api_key = 'klz728yv89qrljzs'\n",
        "api_secret = '4vhxunujbp17i8da0y1tiy7ayde4h5o8'\n",
        "kite = KiteConnect(api_key=api_key)\n",
        "print(\"Login URL:\", kite.login_url())\n",
        "request_token = input(\"Enter request token: \")\n",
        "data = kite.generate_session(request_token, api_secret=api_secret)\n",
        "access_token = data[\"access_token\"]\n",
        "kite.set_access_token(access_token)\n",
        "\n",
        "# Fetch historical data\n",
        "def fetch_historical_data(kite, instrument_token, start_date, end_date, interval, csv_filename):\n",
        "    delta = dt.timedelta(days=60)\n",
        "    current_date = start_date\n",
        "    all_data = []\n",
        "\n",
        "    while current_date < end_date:\n",
        "        to_date = min(current_date + delta, end_date)\n",
        "        data = kite.historical_data(instrument_token, current_date, to_date, interval)\n",
        "        all_data.extend(data)\n",
        "        current_date = to_date + dt.timedelta(days=1)\n",
        "        time.sleep(1)  # Avoid hitting API rate limits\n",
        "\n",
        "    df = pd.DataFrame(all_data)\n",
        "    df.to_csv(csv_filename, mode='w', index=False, header=True)\n",
        "    return df\n",
        "\n",
        "# Fetch historical data\n",
        "instrument_token = '738561' #INFY\n",
        "start_date = dt.datetime(2017, 1, 1)\n",
        "end_date = dt.datetime(2023, 12, 31)\n",
        "interval = 'minute'\n",
        "csv_filename = 'historical_data.csv'\n",
        "\n",
        "df = fetch_historical_data(kite, instrument_token, start_date, end_date, interval, csv_filename)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq3BUJQDWMvr",
        "outputId": "1940a51d-9e7c-43af-8404-146eff4e14b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login URL: https://kite.zerodha.com/connect/login?api_key=klz728yv89qrljzs&v=3\n",
            "Enter request token: rI3J4wbhiSKVoLoKbwKda903z8QHKb83\n",
            "                       date    open    high     low   close  volume\n",
            "0 2017-01-02 09:15:00+05:30  511.45  512.70  510.55  510.80   32510\n",
            "1 2017-01-02 09:16:00+05:30  511.25  511.55  510.95  511.30   15816\n",
            "2 2017-01-02 09:17:00+05:30  511.45  511.45  507.30  507.30   56062\n",
            "3 2017-01-02 09:18:00+05:30  507.40  509.80  506.30  509.80   36745\n",
            "4 2017-01-02 09:19:00+05:30  509.85  510.05  509.35  509.75   22138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering\n",
        "def add_features(df):\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df.set_index('date', inplace=True)\n",
        "    df['SMA_50'] = df['close'].rolling(window=50).mean()\n",
        "    df['SMA_200'] = df['close'].rolling(window=200).mean()\n",
        "    df['RSI'] = calculate_rsi(df, 14)['RSI']\n",
        "    df['Bollinger_Upper'] = calculate_bollinger_bands(df, 20)['Upper_Band']\n",
        "    df['Bollinger_Lower'] = calculate_bollinger_bands(df, 20)['Lower_Band']\n",
        "    df['MACD'] = calculate_macd(df)['MACD']\n",
        "    df['MACD_Signal'] = calculate_macd(df)['Signal_Line']\n",
        "    df['Stochastic_%K'] = calculate_stochastic_oscillator(df, 14)['%K']\n",
        "    df['Stochastic_%D'] = calculate_stochastic_oscillator(df, 14)['%D']\n",
        "    df['Momentum'] = df['close'] / df['close'].shift(10) - 1\n",
        "    df['VWAP'] = calculate_vwap(df)['VWAP']\n",
        "    df['Target'] = np.where(df['close'].shift(-1) > df['close'], 1, 0)\n",
        "    df.dropna(inplace=True)\n",
        "    return df\n",
        "\n",
        "def calculate_rsi(df, window=14):\n",
        "    delta = df['close'].diff(1)\n",
        "    gain = (delta.where(delta > 0, 0)).fillna(0)\n",
        "    loss = (-delta.where(delta < 0, 0)).fillna(0)\n",
        "    avg_gain = gain.rolling(window=window).mean()\n",
        "    avg_loss = loss.rolling(window=window).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    df['RSI'] = 100 - (100 / (1 + rs))\n",
        "    return df\n",
        "\n",
        "def calculate_bollinger_bands(df, window=20):\n",
        "    df['SMA'] = df['close'].rolling(window=window).mean()\n",
        "    df['STD'] = df['close'].rolling(window=window).std()\n",
        "    df['Upper_Band'] = df['SMA'] + (df['STD'] * 2)\n",
        "    df['Lower_Band'] = df['SMA'] - (df['STD'] * 2)\n",
        "    return df\n",
        "\n",
        "def calculate_macd(df, short_window=12, long_window=26, signal_window=9):\n",
        "    df['EMA_12'] = df['close'].ewm(span=short_window, adjust=False).mean()\n",
        "    df['EMA_26'] = df['close'].ewm(span=long_window, adjust=False).mean()\n",
        "    df['MACD'] = df['EMA_12'] - df['EMA_26']\n",
        "    df['Signal_Line'] = df['MACD'].ewm(span=signal_window, adjust=False).mean()\n",
        "    return df\n",
        "\n",
        "def calculate_stochastic_oscillator(df, window=14):\n",
        "    df['L14'] = df['low'].rolling(window=window).min()\n",
        "    df['H14'] = df['high'].rolling(window=window).max()\n",
        "    df['%K'] = (df['close'] - df['L14']) * 100 / (df['H14'] - df['L14'])\n",
        "    df['%D'] = df['%K'].rolling(window=3).mean()\n",
        "    return df\n",
        "\n",
        "def calculate_vwap(df):\n",
        "    df['Cumulative_TP_Volume'] = (df['close'] * df['volume']).cumsum()\n",
        "    df['Cumulative_Volume'] = df['volume'].cumsum()\n",
        "    df['VWAP'] = df['Cumulative_TP_Volume'] / df['Cumulative_Volume']\n",
        "    return df\n",
        "\n",
        "# Add features\n",
        "df = add_features(df)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqd-1RKcWjBE",
        "outputId": "936f971c-06da-434b-b3c6-e38ad42ececd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             open    high     low   close  volume   SMA_50  \\\n",
            "date                                                                         \n",
            "2017-01-02 12:34:00+05:30  514.10  514.15  513.80  514.00    4783  514.129   \n",
            "2017-01-02 12:35:00+05:30  514.00  514.00  513.75  513.80    4384  514.121   \n",
            "2017-01-02 12:36:00+05:30  513.80  514.00  513.70  513.75    5097  514.108   \n",
            "2017-01-02 12:37:00+05:30  513.75  514.00  513.70  513.70    4546  514.095   \n",
            "2017-01-02 12:38:00+05:30  513.70  513.75  513.70  513.70    7186  514.081   \n",
            "\n",
            "                             SMA_200        RSI       SMA       STD  ...  \\\n",
            "date                                                                 ...   \n",
            "2017-01-02 12:34:00+05:30  512.93875  52.941176  513.9775  0.129244  ...   \n",
            "2017-01-02 12:35:00+05:30  512.95375  42.857143  513.9650  0.133870  ...   \n",
            "2017-01-02 12:36:00+05:30  512.96600  40.000000  513.9500  0.140488  ...   \n",
            "2017-01-02 12:37:00+05:30  512.99800  38.888889  513.9400  0.150962  ...   \n",
            "2017-01-02 12:38:00+05:30  513.01750  37.142857  513.9300  0.160099  ...   \n",
            "\n",
            "                              H14         %K         %D  Stochastic_%K  \\\n",
            "date                                                                     \n",
            "2017-01-02 12:34:00+05:30  514.25  58.333333  61.111111      58.333333   \n",
            "2017-01-02 12:35:00+05:30  514.25  25.000000  50.000000      25.000000   \n",
            "2017-01-02 12:36:00+05:30  514.15  20.000000  34.444444      20.000000   \n",
            "2017-01-02 12:37:00+05:30  514.15  10.000000  18.333333      10.000000   \n",
            "2017-01-02 12:38:00+05:30  514.15  10.000000  13.333333      10.000000   \n",
            "\n",
            "                           Stochastic_%D  Momentum  Cumulative_TP_Volume  \\\n",
            "date                                                                       \n",
            "2017-01-02 12:34:00+05:30      61.111111 -0.000292          8.402960e+08   \n",
            "2017-01-02 12:35:00+05:30      50.000000  0.000000          8.425485e+08   \n",
            "2017-01-02 12:36:00+05:30      34.444444 -0.000292          8.451671e+08   \n",
            "2017-01-02 12:37:00+05:30      18.333333 -0.000681          8.475023e+08   \n",
            "2017-01-02 12:38:00+05:30      13.333333 -0.000681          8.511938e+08   \n",
            "\n",
            "                           Cumulative_Volume        VWAP  Target  \n",
            "date                                                              \n",
            "2017-01-02 12:34:00+05:30            1638665  512.793024       0  \n",
            "2017-01-02 12:35:00+05:30            1643049  512.795711       0  \n",
            "2017-01-02 12:36:00+05:30            1648146  512.798662       0  \n",
            "2017-01-02 12:37:00+05:30            1652692  512.801142       0  \n",
            "2017-01-02 12:38:00+05:30            1659878  512.805033       0  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Random Forest Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = df[['SMA_50', 'SMA_200', 'RSI', 'Bollinger_Upper', 'Bollinger_Lower', 'MACD', 'MACD_Signal', 'Stochastic_%K', 'Stochastic_%D', 'Momentum', 'VWAP']]\n",
        "y = df['Target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Random Forest Model Accuracy: {accuracy}\")\n",
        "\n",
        "# Save Random Forest Model\n",
        "import joblib\n",
        "joblib.dump(rf, 'best_rf_model.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP0nfTr0WvQ5",
        "outputId": "679cbc7d-8680-4ba4-d62d-487dc2bc29a1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Accuracy: 0.5410891672228985\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best_rf_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Neural Network Model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Train Neural Network Model Incrementally\n",
        "def create_nn_model(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Check if a pre-trained model exists\n",
        "model_path = 'best_nn_model.h5'\n",
        "if os.path.exists(model_path):\n",
        "    nn_model = load_model(model_path)\n",
        "    print(\"Loaded pre-trained model.\")\n",
        "else:\n",
        "    nn_model = create_nn_model(X_train.shape[1])\n",
        "    print(\"Created new model.\")\n",
        "\n",
        "# Continue training the model\n",
        "nn_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=1)\n",
        "\n",
        "loss, accuracy = nn_model.evaluate(X_test, y_test)\n",
        "print(f\"Neural Network Model Accuracy: {accuracy}\")\n",
        "\n",
        "# Save Neural Network Model\n",
        "nn_model.save(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYeJyjniWyfS",
        "outputId": "67a63e74-a00d-4a83-e549-db3d3aac526e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "14327/14327 [==============================] - 33s 2ms/step - loss: 1.6309 - accuracy: 0.5053 - val_loss: 0.7045 - val_accuracy: 0.5068\n",
            "Epoch 2/10\n",
            "14327/14327 [==============================] - 31s 2ms/step - loss: 0.8249 - accuracy: 0.5107 - val_loss: 0.6951 - val_accuracy: 0.5251\n",
            "Epoch 3/10\n",
            "14327/14327 [==============================] - 30s 2ms/step - loss: 0.7023 - accuracy: 0.5218 - val_loss: 0.6915 - val_accuracy: 0.5286\n",
            "Epoch 4/10\n",
            "14327/14327 [==============================] - 34s 2ms/step - loss: 0.6915 - accuracy: 0.5290 - val_loss: 0.6915 - val_accuracy: 0.5286\n",
            "Epoch 5/10\n",
            "14327/14327 [==============================] - 31s 2ms/step - loss: 0.6915 - accuracy: 0.5290 - val_loss: 0.6915 - val_accuracy: 0.5286\n",
            "Epoch 6/10\n",
            "14327/14327 [==============================] - 34s 2ms/step - loss: 0.6915 - accuracy: 0.5290 - val_loss: 0.6915 - val_accuracy: 0.5286\n",
            "Epoch 7/10\n",
            "14327/14327 [==============================] - 31s 2ms/step - loss: 0.6915 - accuracy: 0.5290 - val_loss: 0.6915 - val_accuracy: 0.5286\n",
            "Epoch 8/10\n",
            "14327/14327 [==============================] - 31s 2ms/step - loss: 0.6915 - accuracy: 0.5290 - val_loss: 0.6915 - val_accuracy: 0.5286\n",
            "Epoch 9/10\n",
            "14327/14327 [==============================] - 32s 2ms/step - loss: 0.6915 - accuracy: 0.5290 - val_loss: 0.6915 - val_accuracy: 0.5286\n",
            "Epoch 10/10\n",
            "14327/14327 [==============================] - 35s 2ms/step - loss: 0.6915 - accuracy: 0.5290 - val_loss: 0.6916 - val_accuracy: 0.5286\n",
            "3980/3980 [==============================] - 6s 1ms/step - loss: 0.6917 - accuracy: 0.5276\n",
            "Neural Network Model Accuracy: 0.5275668501853943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W2SfvP7kVq-v"
      },
      "outputs": [],
      "source": [
        "# Backtesting Strategy with Balance Check, Stop Loss, and Target Profit\n",
        "def backtest_strategy(model, data, initial_balance=100000, stop_loss_pct=0.02, target_profit_pct=0.05):\n",
        "    balance = initial_balance\n",
        "    position = None\n",
        "    buy_price = 0\n",
        "    trade_log = []\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "        if position is None:\n",
        "            features = row[['SMA_50', 'SMA_200', 'RSI', 'Bollinger_Upper', 'Bollinger_Lower', 'MACD', 'MACD_Signal', 'Stochastic_%K', 'Stochastic_%D', 'Momentum', 'VWAP']].values.reshape(1, -1)\n",
        "            prediction = model.predict(features)[0]\n",
        "\n",
        "            if prediction == 1:\n",
        "                buy_price = row['close']\n",
        "                position = 'long'\n",
        "                trade_log.append((index, 'buy', buy_price))\n",
        "                print(f\"Buying at {buy_price}\")\n",
        "\n",
        "        elif position == 'long':\n",
        "            current_price = row['close']\n",
        "            if current_price <= buy_price * (1 - stop_loss_pct):\n",
        "                balance -= (buy_price - current_price)\n",
        "                position = None\n",
        "                trade_log.append((index, 'stop_loss', current_price))\n",
        "                print(f\"Stop loss at {current_price}\")\n",
        "            elif current_price >= buy_price * (1 + target_profit_pct):\n",
        "                balance += (current_price - buy_price)\n",
        "                position = None\n",
        "                trade_log.append((index, 'target_profit', current_price))\n",
        "                print(f\"Target profit at {current_price}\")\n",
        "\n",
        "    return balance, trade_log\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fetch historical data for backtest\n",
        "\n",
        "# Authentication and data fetching\n",
        "import pandas as pd\n",
        "from kiteconnect import KiteConnect\n",
        "import datetime as dt\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "api_key = 'klz728yv89qrljzs'\n",
        "api_secret = '4vhxunujbp17i8da0y1tiy7ayde4h5o8'\n",
        "kite = KiteConnect(api_key=api_key)\n",
        "print(\"Login URL:\", kite.login_url())\n",
        "request_token = input(\"Enter request token: \")\n",
        "data = kite.generate_session(request_token, api_secret=api_secret)\n",
        "access_token = data[\"access_token\"]\n",
        "kite.set_access_token(access_token)\n",
        "\n",
        "# Fetch historical data\n",
        "def fetch_historical_data(kite, instrument_token, start_date, end_date, interval, csv_filename):\n",
        "    delta = dt.timedelta(days=60)\n",
        "    current_date = start_date\n",
        "    all_data = []\n",
        "\n",
        "    while current_date < end_date:\n",
        "        to_date = min(current_date + delta, end_date)\n",
        "        data = kite.historical_data(instrument_token, current_date, to_date, interval)\n",
        "        all_data.extend(data)\n",
        "        current_date = to_date + dt.timedelta(days=1)\n",
        "        time.sleep(1)  # Avoid hitting API rate limits\n",
        "\n",
        "    df = pd.DataFrame(all_data)\n",
        "    df.to_csv(csv_filename, mode='w', index=False, header=True)\n",
        "    return df\n",
        "\n",
        "instrument_token = '738561' #INFY\n",
        "start_date = dt.datetime(2017, 1, 1)\n",
        "end_date = dt.datetime(2023, 12, 31)\n",
        "interval = 'minute'\n",
        "csv_filename = 'historical_data.csv'\n",
        "\n",
        "df_backtest = fetch_historical_data(kite, instrument_token, start_date, end_date, interval, 'backtest_data.csv')\n",
        "df_backtest = add_features(df_backtest)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "RC6Z-t93lRsO",
        "outputId": "c3405f0a-db4e-4513-8b7b-7d47aa4838a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'fetch_historical_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-740025c61a6a>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcsv_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'historical_data.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_backtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_historical_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstrument_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'backtest_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf_backtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_backtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'fetch_historical_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Backtesting with Random Forest Model\n",
        "final_balance, trade_log = backtest_strategy(rf, df_backtest)\n",
        "print(f\"Final Balance (Random Forest): {final_balance}\")\n",
        "print(trade_log)\n",
        "\n"
      ],
      "metadata": {
        "id": "dqYEJHs6ipCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Backtesting with Neural Network Model\n",
        "final_balance, trade_log = backtest_strategy(nn_model, df_backtest)\n",
        "print(f\"Final Balance (Neural Network): {final_balance}\")\n",
        "print(trade_log)"
      ],
      "metadata": {
        "id": "_uq2gw3bWhg6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}